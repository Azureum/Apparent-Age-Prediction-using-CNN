{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QInputDialog, QLineEdit, QFileDialog, QPushButton\n",
    "from PyQt5.QtGui import QIcon\n",
    "from PyQt5.QtCore import pyqtSlot\n",
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, add, Dense, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "sys.setrecursionlimit(2 ** 20)\n",
    "np.random.seed(2 ** 10)\n",
    "\n",
    "\n",
    "class WideResNet:\n",
    "    def __init__(self, image_size, depth=16, k=8):\n",
    "        self._depth = depth\n",
    "        self._k = k\n",
    "        self._dropout_probability = 0\n",
    "        self._weight_decay = 0.0005\n",
    "        self._use_bias = False\n",
    "        self._weight_init = \"he_normal\"\n",
    "\n",
    "        if K.image_dim_ordering() == \"th\":\n",
    "            logging.debug(\"image_dim_ordering = 'th'\")\n",
    "            self._channel_axis = 1\n",
    "            self._input_shape = (3, image_size, image_size)\n",
    "        else:\n",
    "            logging.debug(\"image_dim_ordering = 'tf'\")\n",
    "            self._channel_axis = -1\n",
    "            self._input_shape = (image_size, image_size, 3)\n",
    "\n",
    "    # Wide residual network http://arxiv.org/abs/1605.07146\n",
    "    def _wide_basic(self, n_input_plane, n_output_plane, stride):\n",
    "        def f(net):\n",
    "            # format of conv_params:\n",
    "            #               [ [kernel_size=(\"kernel width\", \"kernel height\"),\n",
    "            #               strides=\"(stride_vertical,stride_horizontal)\",\n",
    "            #               padding=\"same\" or \"valid\"] ]\n",
    "            # B(3,3): orignal <<basic>> block\n",
    "            conv_params = [[3, 3, stride, \"same\"],\n",
    "                           [3, 3, (1, 1), \"same\"]]\n",
    "\n",
    "            n_bottleneck_plane = n_output_plane\n",
    "\n",
    "            # Residual block\n",
    "            for i, v in enumerate(conv_params):\n",
    "                if i == 0:\n",
    "                    if n_input_plane != n_output_plane:\n",
    "                        net = BatchNormalization(axis=self._channel_axis)(net)\n",
    "                        net = Activation(\"relu\")(net)\n",
    "                        convs = net\n",
    "                    else:\n",
    "                        convs = BatchNormalization(axis=self._channel_axis)(net)\n",
    "                        convs = Activation(\"relu\")(convs)\n",
    "\n",
    "                    convs = Conv2D(n_bottleneck_plane, kernel_size=(v[0], v[1]),\n",
    "                                          strides=v[2],\n",
    "                                          padding=v[3],\n",
    "                                          kernel_initializer=self._weight_init,\n",
    "                                          kernel_regularizer=l2(self._weight_decay),\n",
    "                                          use_bias=self._use_bias)(convs)\n",
    "                else:\n",
    "                    convs = BatchNormalization(axis=self._channel_axis)(convs)\n",
    "                    convs = Activation(\"relu\")(convs)\n",
    "                    if self._dropout_probability > 0:\n",
    "                        convs = Dropout(self._dropout_probability)(convs)\n",
    "                    convs = Conv2D(n_bottleneck_plane, kernel_size=(v[0], v[1]),\n",
    "                                          strides=v[2],\n",
    "                                          padding=v[3],\n",
    "                                          kernel_initializer=self._weight_init,\n",
    "                                          kernel_regularizer=l2(self._weight_decay),\n",
    "                                          use_bias=self._use_bias)(convs)\n",
    "\n",
    "            # Shortcut Connection: identity function or 1x1 convolutional\n",
    "            #  (depends on difference between input & output shape - this\n",
    "            #   corresponds to whether we are using the first block in each\n",
    "            #   group; see _layer() ).\n",
    "            if n_input_plane != n_output_plane:\n",
    "                shortcut = Conv2D(n_output_plane, kernel_size=(1, 1),\n",
    "                                         strides=stride,\n",
    "                                         padding=\"same\",\n",
    "                                         kernel_initializer=self._weight_init,\n",
    "                                         kernel_regularizer=l2(self._weight_decay),\n",
    "                                         use_bias=self._use_bias)(net)\n",
    "            else:\n",
    "                shortcut = net\n",
    "\n",
    "            return add([convs, shortcut])\n",
    "\n",
    "        return f\n",
    "\n",
    "\n",
    "    # \"Stacking Residual Units on the same stage\"\n",
    "    def _layer(self, block, n_input_plane, n_output_plane, count, stride):\n",
    "        def f(net):\n",
    "            net = block(n_input_plane, n_output_plane, stride)(net)\n",
    "            for i in range(2, int(count + 1)):\n",
    "                net = block(n_output_plane, n_output_plane, stride=(1, 1))(net)\n",
    "            return net\n",
    "\n",
    "        return f\n",
    "\n",
    "#    def create_model(self):\n",
    "    def __call__(self):\n",
    "        logging.debug(\"Creating model...\")\n",
    "\n",
    "        assert ((self._depth - 4) % 6 == 0)\n",
    "        n = (self._depth - 4) / 6\n",
    "\n",
    "        inputs = Input(shape=self._input_shape)\n",
    "\n",
    "        n_stages = [16, 16 * self._k, 32 * self._k, 64 * self._k]\n",
    "\n",
    "        conv1 = Conv2D(filters=n_stages[0], kernel_size=(3, 3),\n",
    "                              strides=(1, 1),\n",
    "                              padding=\"same\",\n",
    "                              kernel_initializer=self._weight_init,\n",
    "                              kernel_regularizer=l2(self._weight_decay),\n",
    "                              use_bias=self._use_bias)(inputs)  # \"One conv at the beginning (spatial size: 32x32)\"\n",
    "\n",
    "        # Add wide residual blocks\n",
    "        block_fn = self._wide_basic\n",
    "        conv2 = self._layer(block_fn, n_input_plane=n_stages[0], n_output_plane=n_stages[1], count=n, stride=(1, 1))(conv1)\n",
    "        conv3 = self._layer(block_fn, n_input_plane=n_stages[1], n_output_plane=n_stages[2], count=n, stride=(2, 2))(conv2)\n",
    "        conv4 = self._layer(block_fn, n_input_plane=n_stages[2], n_output_plane=n_stages[3], count=n, stride=(2, 2))(conv3)\n",
    "        batch_norm = BatchNormalization(axis=self._channel_axis)(conv4)\n",
    "        relu = Activation(\"relu\")(batch_norm)\n",
    "\n",
    "        # Classifier block\n",
    "        pool = AveragePooling2D(pool_size=(8, 8), strides=(1, 1), padding=\"same\")(relu)\n",
    "        flatten = Flatten()(pool)\n",
    "        predictions_g = Dense(units=2, kernel_initializer=self._weight_init, use_bias=self._use_bias,\n",
    "                              kernel_regularizer=l2(self._weight_decay), activation=\"softmax\")(flatten)\n",
    "        predictions_a = Dense(units=101, kernel_initializer=self._weight_init, use_bias=self._use_bias,\n",
    "                              kernel_regularizer=l2(self._weight_decay), activation=\"softmax\")(flatten)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=[predictions_g, predictions_a])\n",
    "\n",
    "        return model\n",
    " \n",
    "class App(QWidget):\n",
    " \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title = 'Age Prediction from facial images'\n",
    "        self.left = 10\n",
    "        self.top = 10\n",
    "        self.width = 640\n",
    "        self.height = 480\n",
    "        self.initUI()\n",
    " \n",
    "    def initUI(self):\n",
    "        self.setWindowTitle(self.title)\n",
    "        self.setGeometry(self.left, self.top, self.width, self.height)\n",
    "        button = QPushButton('Input file', self)\n",
    "        button.setToolTip('Input an image:')\n",
    "        button.move(100,70) \n",
    "        button.clicked.connect(self.on_click)\n",
    "        self.show()\n",
    "\n",
    "    def openFileNameDialog(self):    \n",
    "        options = QFileDialog.Options()\n",
    "        options |= QFileDialog.DontUseNativeDialog\n",
    "        fileName, _ = QFileDialog.getOpenFileName(self,\"QFileDialog.getOpenFileName()\", \"\",\"All Files (*);;Python Files (*.py)\", options=options)\n",
    "        if fileName:\n",
    "            self.predict()\n",
    "\n",
    "    @pyqtSlot()\n",
    "    def on_click(self):\n",
    "        self.openFileNameDialog()\n",
    "\n",
    "    def draw_label(self, image, point, label, font_scale=1, thickness=2):\n",
    "        size = cv2.getTextSize(label,font_scale, thickness)[0]\n",
    "        print(size)\n",
    "        x, y = point\n",
    "        cv2.rectangle(image, (x, y - size[1]), (x + size[0], y), (255, 0, 0), cv2.FILLED)\n",
    "        cv2.putText(image, label, point, font, font_scale, (255, 255, 255), thickness)\n",
    "\n",
    "\n",
    "    def predict(self):\n",
    "        depth = 16\n",
    "        k = 8\n",
    "        weight_file = \"weights.18-4.06.hdf5\"\n",
    "\n",
    "        detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "        img_size = 64\n",
    "        model = WideResNet(img_size, depth=depth, k=k)()\n",
    "        model.load_weights(weight_file)\n",
    "\n",
    "        img = cv2.imread('Testing/trump.jpg')\n",
    "\n",
    "        input_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_h, img_w, _ = np.shape(input_img)\n",
    "\n",
    "        detected = detector(input_img, 1)\n",
    "        faces = np.empty((len(detected), img_size, img_size, 3))\n",
    "        #print(faces.shape)\n",
    "        for i, d in enumerate(detected):\n",
    "            x1, y1, x2, y2, w, h = d.left(), d.top(), d.right() + 1, d.bottom() + 1, d.width(), d.height()\n",
    "            xw1 = max(int(x1 - 0.4 * w), 0)\n",
    "            yw1 = max(int(y1 - 0.4 * h), 0)\n",
    "            xw2 = min(int(x2 + 0.4 * w), img_w - 1)\n",
    "            yw2 = min(int(y2 + 0.4 * h), img_h - 1)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            faces[i,:,:,:] = cv2.resize(img[yw1:yw2 + 1, xw1:xw2 + 1, :], (img_size, img_size))\n",
    "            results = model.predict(np.expand_dims(faces[i],axis=0))\n",
    "            #print((np.expand_dims(faces[i],axis=0).shape))\n",
    "            #plt.imshow(faces)\n",
    "            predicted_genders = results[0]\n",
    "            #print(predicted_genders)\n",
    "            ages=np.zeros(101)\n",
    "            for j in range(101):\n",
    "                ages[j]=j\n",
    "            top3=(sorted(zip(results[1][0],ages), reverse=True)[:3])\n",
    "            print (top3)\n",
    "            answer_age=top3[0][1]\n",
    "            label = \"{}, {}\".format(int(answer_age),\n",
    "                                    \"F\" if predicted_genders[0][0] > 0.5 else \"M\")\n",
    "            self.draw_label(self, img, (d.left(), d.top()), label)\n",
    "\n",
    "\n",
    "        plt.imshow(img)\n",
    "\n",
    " \n",
    "   \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    ex = App()\n",
    "    sys.exit(app.exec_())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
