{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HAN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rachit-shah/Apparent-Age-Prediction-using-CNN/blob/master/HAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "BToPi2JX6jzd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Data and Glove Model From Drive"
      ]
    },
    {
      "metadata": {
        "id": "JvS3pf0t6zsk",
        "colab_type": "code",
        "outputId": "19fdc784-440b-4fc0-f1a6-3328333a762b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e9s7l5uI7QWJ",
        "colab_type": "code",
        "outputId": "dfeeaa33-763e-431a-ce48-d73af51b6bae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "%matplotlib inline\n",
        "import nltk\n",
        "nltk.download('popular')\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer,text_to_word_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D, Dropout, LSTM, GRU, Bidirectional, SpatialDropout1D, TimeDistributed\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding, Flatten\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction import text \n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import nltk.corpus\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from keras.layers import Embedding\n",
        "\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "z8c7Ay-J7Qwh",
        "colab_type": "code",
        "outputId": "ab72802f-5f41-4130-df89-80201acfff1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "!cp gdrive/'My Drive'/bbc-fulltext.zip .\n",
        "!cp gdrive/'My Drive'/glove.6B.zip .\n",
        "!unzip bbc-fulltext.zip > out.txt\n",
        "!rm bbc/README.TXT\n",
        "!unzip glove.6B.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ew62XD1v790p",
        "colab_type": "code",
        "outputId": "cfe587cc-227e-4d75-b31f-29f2ddebd228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "cell_type": "code",
      "source": [
        "#Read Data\n",
        "categories = ['business','entertainment','politics','sport','tech']\n",
        "df = pd.DataFrame([],columns=['category','id','text'])\n",
        "for cat in categories:\n",
        "  for file in os.listdir(\"bbc/\"+cat):\n",
        "      if file.endswith(\".txt\"):\n",
        "          filepath = os.path.join(\"bbc/\"+cat, file)\n",
        "          text = open(filepath,'r', errors='ignore').read()\n",
        "          s = pd.Series([cat,int(filepath.split('/')[-1][:-4]),text],index=['category','id','text'])\n",
        "          df = df.append(s,ignore_index=True)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>128</td>\n",
              "      <td>Qantas sees profits fly to record\\n\\nAustralia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>139</td>\n",
              "      <td>German jobless rate at new record\\n\\nMore than...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>389</td>\n",
              "      <td>Egypt to sell off state-owned bank\\n\\nThe Egyp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>479</td>\n",
              "      <td>Ford gains from finance not cars\\n\\nFord, the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>business</td>\n",
              "      <td>233</td>\n",
              "      <td>Bat spit drug firm goes to market\\n\\nA German ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category   id                                               text\n",
              "0  business  128  Qantas sees profits fly to record\\n\\nAustralia...\n",
              "1  business  139  German jobless rate at new record\\n\\nMore than...\n",
              "2  business  389  Egypt to sell off state-owned bank\\n\\nThe Egyp...\n",
              "3  business  479  Ford gains from finance not cars\\n\\nFord, the ...\n",
              "4  business  233  Bat spit drug firm goes to market\\n\\nA German ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "uZXIyNwn8tT3",
        "colab_type": "code",
        "outputId": "6e340660-1b5c-45dc-ff8a-47899b3efc99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "#WordCloud\n",
        "cat = df['category'].unique()\n",
        "\n",
        "for i in range(0,len(cat)):\n",
        "    words = ' '.join(df.loc[df['category']==cat[i], 'text'])\n",
        "\n",
        "    wordcloud = WordCloud( \n",
        "                          stopwords=STOPWORDS,\n",
        "                          background_color='white',\n",
        "                          width=800,\n",
        "                          height=400\n",
        "                ).generate(words)\n",
        "    print(cat[i])\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "words = ' '.join(df.loc[:, 'text'])\n",
        "\n",
        "wordcloud = WordCloud( \n",
        "                      stopwords=STOPWORDS,\n",
        "                      background_color='white',\n",
        "                      width=800,\n",
        "                      height=400\n",
        "            ).generate(words)\n",
        "print(\"ALL Categories:\")\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "'''"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#WordCloud\\ncat = df[\\'category\\'].unique()\\n\\nfor i in range(0,len(cat)):\\n    words = \\' \\'.join(df.loc[df[\\'category\\']==cat[i], \\'text\\'])\\n\\n    wordcloud = WordCloud( \\n                          stopwords=STOPWORDS,\\n                          background_color=\\'white\\',\\n                          width=800,\\n                          height=400\\n                ).generate(words)\\n    print(cat[i])\\n    plt.figure(figsize=(10, 5))\\n    plt.imshow(wordcloud)\\n    plt.axis(\\'off\\')\\n    plt.show()\\n\\nwords = \\' \\'.join(df.loc[:, \\'text\\'])\\n\\nwordcloud = WordCloud( \\n                      stopwords=STOPWORDS,\\n                      background_color=\\'white\\',\\n                      width=800,\\n                      height=400\\n            ).generate(words)\\nprint(\"ALL Categories:\")\\nplt.figure(figsize=(10, 5))\\nplt.imshow(wordcloud)\\nplt.axis(\\'off\\')\\nplt.show()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "JR2fsHlbr_Tj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Label Encoder\n",
        "#### Use inverse_transform at the end after predicting"
      ]
    },
    {
      "metadata": {
        "id": "385fGoXNldB0",
        "colab_type": "code",
        "outputId": "96e15b17-1694-4939-b87a-bca4206bb7a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "cell_type": "code",
      "source": [
        "y = df['category']\n",
        "X = df.drop(['category','id'],axis=1)\n",
        "X_train, X_test, y_train, y_test  = train_test_split(X,y,stratify=y, test_size=0.2, random_state=123)\n",
        "X_train = X_train.reset_index(drop=True)\n",
        "X_test = X_test.reset_index(drop=True)\n",
        "y_test = y_test.reset_index(drop=True)\n",
        "\n",
        "print('before: %s ...' %y_train[:5])\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(y_train)\n",
        "y_train = le.transform(y_train)\n",
        "\n",
        "print('after: %s ...' %y_train)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before: 1508       sport\n",
            "1908        tech\n",
            "2104        tech\n",
            "2019        tech\n",
            "1245    politics\n",
            "Name: category, dtype: object ...\n",
            "after: [3 4 4 ... 1 0 2] ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n9jqvQtYDhR0",
        "colab_type": "code",
        "outputId": "6de62ef8-b8a1-4166-b39b-92dfff03867d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        }
      },
      "cell_type": "code",
      "source": [
        "print(np.bincount(y_train))\n",
        "print(y.value_counts())\n",
        "print(le.inverse_transform([i for i in range(5)]))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[408 309 333 409 321]\n",
            "sport            511\n",
            "business         510\n",
            "politics         417\n",
            "tech             401\n",
            "entertainment    386\n",
            "Name: category, dtype: int64\n",
            "['business' 'entertainment' 'politics' 'sport' 'tech']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1e6g_BjOsZ3i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocess Data - (split by \\n, remove periods, remove slashes)"
      ]
    },
    {
      "metadata": {
        "id": "eJwCB-hGlWXW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0a2f257d-a49b-491c-a0ed-00e5fab5bc3d"
      },
      "cell_type": "code",
      "source": [
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_SENT_LENGTH = 50\n",
        "MAX_SENTS = 50\n",
        "MAX_NB_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "VALIDATION_SPLIT = 0.2\n",
        "embeddings_index = {}\n",
        "with open('glove.6B.100d.txt') as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_3Iv6MC3s26i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(X):\n",
        "  return X.map(lambda x: x.lower().split(\"\\n\")).map(lambda x: [y.split(\". \") for y in x]).map(lambda x: [i.replace('\\'','') for sl in x for i in sl if i is not ''])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6EgQMq_CtK8d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Preprocess both train and test separately\n",
        "def replace_punct(st,punct):\n",
        "  for i in punct:\n",
        "    if i==\"..\":\n",
        "      st = st.replace(\"..\",'.')\n",
        "    elif i==\"--\" or i == '-':\n",
        "      st = st.replace(i,' ')\n",
        "    else:\n",
        "      st = st.replace(i,'')\n",
        "  return st\n",
        "punct = word_tokenize(string.punctuation) + ['``','...','..','\\'s','--','-','n\\'t','\\'','(',')','[',']','{','}']\n",
        "texts = preprocess(X_train['text']).map(lambda x: '. '.join(x)).map(lambda x: replace_punct(x,punct))\n",
        "test_text = preprocess(X_test['text']).map(lambda x: '. '.join(x)).map(lambda x: replace_punct(x,punct))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wx7rLmbykkXS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "articles = texts.map(lambda x: sent_tokenize(x))\n",
        "test_articles = test_text.map(lambda x: sent_tokenize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6bVCPt-Bl0r_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "882fbe22-5305-43cf-ff1a-04194b68f55d"
      },
      "cell_type": "code",
      "source": [
        "li = []\n",
        "se = []\n",
        "for x in articles:\n",
        "  li.append(len(x))\n",
        "  for y in x:\n",
        "    se.append(len(y.split()))\n",
        "  \n",
        "#plt.boxplot(li,showcaps=True)\n",
        "plt.boxplot(se,showcaps=True)\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boxes': [<matplotlib.lines.Line2D at 0x7f3d42fb3470>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7f3d42fb3a20>,\n",
              "  <matplotlib.lines.Line2D at 0x7f3d42fb59e8>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7f3d42fb5198>],\n",
              " 'means': [],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7f3d42fb5358>],\n",
              " 'whiskers': [<matplotlib.lines.Line2D at 0x7f3d42fb37f0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f3d42fb3da0>]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xGvbU8VulRqC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "33266f60-3c6e-4c5a-9d0a-46cb429a7236"
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "data = np.zeros((len(texts), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
        "\n",
        "for i, sentences in enumerate(articles):\n",
        "    for j, sent in enumerate(sentences):\n",
        "        if j< MAX_SENTS:\n",
        "            wordTokens = text_to_word_sequence(sent)\n",
        "            k=0\n",
        "            for _, word in enumerate(wordTokens):\n",
        "                if k<MAX_SENT_LENGTH and tokenizer.word_index[word]<MAX_NB_WORDS:\n",
        "                    data[i,j,k] = tokenizer.word_index[word]\n",
        "                    k=k+1\n",
        "                    \n",
        "word_index = tokenizer.word_index\n",
        "print('No. of %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of 28415 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "12KRmMu8tK11",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_data = np.zeros((len(test_text), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
        "\n",
        "for i, sentences in enumerate(test_articles):\n",
        "    for j, sent in enumerate(sentences):\n",
        "        if j< MAX_SENTS:\n",
        "            wordTokens = text_to_word_sequence(sent)\n",
        "            k=0\n",
        "            for _, word in enumerate(wordTokens):\n",
        "                if k<MAX_SENT_LENGTH and word in tokenizer.word_index and tokenizer.word_index[word]<MAX_NB_WORDS:\n",
        "                    test_data[i,j,k] = tokenizer.word_index[word]\n",
        "                    k=k+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wb3DxolUuYHy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92e98535-3223-477c-b443-c9bf93cd41af"
      },
      "cell_type": "code",
      "source": [
        "test_data.shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(445, 50, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "cmPomOGXoP0f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "68aa6d8c-25fe-44ae-801a-e4c49cdc3178"
      },
      "cell_type": "code",
      "source": [
        "labels = to_categorical(np.asarray(y_train))\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "# split the data into a training set and a validation set\n",
        "np.random.seed(123)\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "xtrain = data[:-nb_validation_samples]\n",
        "ytrain = labels[:-nb_validation_samples]\n",
        "xval = data[-nb_validation_samples:]\n",
        "yval = labels[-nb_validation_samples:]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (1780, 50, 50)\n",
            "Shape of label tensor: (1780, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wme2RkYu2UR0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f617317e-a0d4-4993-c87a-8eeba1487275"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "#Stop Words and Lemmatization   \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stopw = nltk.corpus.stopwords.words('english')\n",
        "punct = string.punctuation\n",
        "punct = word_tokenize(punct)\n",
        "punct += ['.','``','...','\\'s','--','-','n\\'t','\\'']\n",
        "stopw += punct\n",
        "def token_stop(text):\n",
        "    global stopw\n",
        "    global lemmatizer\n",
        "    words = word_tokenize(text)\n",
        "    filtered = [lemmatizer.lemmatize(w) for w in words if not w in stopw]\n",
        "    return filtered\n",
        "  \n",
        "X_train['text'] = X_train['text'].map(lambda x: [token_stop(i) for i in x]).map(lambda x: [i for sl in x for i in sl])\n",
        "X_test['text'] = X_test['text'].map(lambda x: [token_stop(i) for i in x]).map(lambda x: [i for sl in x for i in sl])\n",
        "'''"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n#Stop Words and Lemmatization   \\nlemmatizer = WordNetLemmatizer()\\nstopw = nltk.corpus.stopwords.words('english')\\npunct = string.punctuation\\npunct = word_tokenize(punct)\\npunct += ['.','``','...',''s','--','-','n't',''']\\nstopw += punct\\ndef token_stop(text):\\n    global stopw\\n    global lemmatizer\\n    words = word_tokenize(text)\\n    filtered = [lemmatizer.lemmatize(w) for w in words if not w in stopw]\\n    return filtered\\n  \\nX_train['text'] = X_train['text'].map(lambda x: [token_stop(i) for i in x]).map(lambda x: [i for sl in x for i in sl])\\nX_test['text'] = X_test['text'].map(lambda x: [token_stop(i) for i in x]).map(lambda x: [i for sl in x for i in sl])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "VofHdiAqIRqc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create glove embedding matrix\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iuZyVOsKKD6T",
        "colab_type": "code",
        "outputId": "28c547f4-2de4-4e7b-a3c8-84090c617c8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Map label name to its index\n",
        "labels_index = {}\n",
        "for i in range(5):\n",
        "  name = le.inverse_transform([i])[0]\n",
        "  labels_index[name] = i\n",
        "labels_index"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'business': 0, 'entertainment': 1, 'politics': 2, 'sport': 3, 'tech': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "e18TBVrC9iwT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ]
    },
    {
      "metadata": {
        "id": "3xOvfu82wTmg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Keras Glove Embedding layer\n",
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SENT_LENGTH,\n",
        "                            trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ijGeDWg6-XsZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_name = \"HAN\"\n",
        "checkpointer = ModelCheckpoint(model_name + \"_weights.{epoch:02d}-{val_loss:.2f}.hdf5\", monitor=\"val_loss\", verbose=1,\n",
        "                               save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "tensorboard_han = TensorBoard(log_dir='./Graph_HAN', histogram_freq=1,write_graph=True,write_grads=True, write_images=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "53s9TZ_mI_XY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "7d7c6126-650b-4abc-98ca-804f4c889319"
      },
      "cell_type": "code",
      "source": [
        "sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sentence_input)\n",
        "lstm_layer = Bidirectional(LSTM(100,dropout=0.35))(embedded_sequences)\n",
        "sentEncoder = Model(sentence_input, lstm_layer)\n",
        "\n",
        "article_input = Input(shape=(MAX_SENTS,MAX_SENT_LENGTH), dtype='int32')\n",
        "article_encoder = TimeDistributed(sentEncoder)(article_input)\n",
        "lstm_layer_sent = Bidirectional(LSTM(100,dropout=0.35))(article_encoder)\n",
        "preds = Dense(len(labels_index), activation='softmax')(lstm_layer_sent)\n",
        "han_model = Model(article_input, preds)\n",
        "\n",
        "han_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])\n",
        "han_model.summary()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        (None, 50, 50)            0         \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 50, 200)           3002400   \n",
            "_________________________________________________________________\n",
            "bidirectional_14 (Bidirectio (None, 200)               240800    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 5)                 1005      \n",
            "=================================================================\n",
            "Total params: 3,244,205\n",
            "Trainable params: 402,605\n",
            "Non-trainable params: 2,841,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fp3SQDq3-tfj",
        "colab_type": "code",
        "outputId": "3dc04448-af33-4a4d-9984-e83340427b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1746
        }
      },
      "cell_type": "code",
      "source": [
        "stmillis = int(round(time.time() * 1000))\n",
        "history = han_model.fit(xtrain, ytrain, validation_data=(xval, yval),\n",
        "          epochs=50, batch_size=128, callbacks=[checkpointer, early_stopping, tensorboard_han])\n",
        "endmillis = int(round(time.time() * 1000))\n",
        "print(\"Time taken: \", endmillis - stmillis)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1424 samples, validate on 356 samples\n",
            "Epoch 1/50\n",
            "1424/1424 [==============================] - 13s 9ms/step - loss: 1.3984 - acc: 0.4600 - val_loss: 0.8720 - val_acc: 0.6966\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.87198, saving model to HAN_weights.01-0.87.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'input_16' with dtype int32 and shape [?,50,50]\n\t [[{{node input_16}}]]\n\t [[{{node time_distributed_9/bidirectional_13/cond_6/Switch}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-145-b47c4eaab737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstmillis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m history = han_model.fit(xtrain, ytrain, validation_data=(xval, yval),\n\u001b[0;32m----> 3\u001b[0;31m           epochs=50, batch_size=128, callbacks=[checkpointer, early_stopping, tensorboard_han])\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mendmillis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time taken: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendmillis\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstmillis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                             \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    939\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m                     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                     \u001b[0msummary_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'input_16' with dtype int32 and shape [?,50,50]\n\t [[node input_16 (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517) ]]\n\t [[node time_distributed_9/bidirectional_13/cond_6/Switch (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3058) ]]\n\nCaused by op 'input_16', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-133-ace91a34fdbc>\", line 6, in <module>\n    article_input = Input(shape=(MAX_SENTS,MAX_SENT_LENGTH), dtype='int32')\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/input_layer.py\", line 178, in Input\n    input_tensor=tensor)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/input_layer.py\", line 87, in __init__\n    name=self.name)\n  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 517, in placeholder\n    x = tf.placeholder(dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\", line 2077, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 5791, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'input_16' with dtype int32 and shape [?,50,50]\n\t [[node input_16 (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517) ]]\n\t [[node time_distributed_9/bidirectional_13/cond_6/Switch (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3058) ]]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Z73Z42jPBsd3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig=plt.figure()\n",
        "plt.plot(history.history['acc'],'r',linewidth=3.0)\n",
        "plt.plot(history.history['val_acc'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "plt.title('Accuracy Curves : CNN',fontsize=16)\n",
        "fig.savefig('accuracy_cnn.png')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8nUIMMQi_KrR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save the trained weights\n",
        "han_model.save(model_name + \".h5\")\n",
        "\n",
        "# Save model config as json\n",
        "model_json = han_model.to_json()\n",
        "with open(model_name + \".json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "# Persist the model to your google drive [VERY IMPORTANT]\n",
        "!cp HAN.* gdrive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ja5gH7GZvxWy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7BAwr4x19nMo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Predict on Test Data"
      ]
    },
    {
      "metadata": {
        "id": "vIBlzM5zFVhG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def find_test_acc(prediction):\n",
        "  count = 0\n",
        "  t = 0\n",
        "  for pred in prediction:\n",
        "    p = pred.argmax()\n",
        "    name = le.inverse_transform([p])\n",
        "    #print(count)\n",
        "    #print(y_test.loc[count])\n",
        "    if name == y_test.loc[count]:\n",
        "      t+=1\n",
        "    count+=1\n",
        "  print('Test Accuracy:',(t/count)*100,\"%\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1sM8QeKfJgRr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_test(model):\n",
        "  prediction = model.predict(test_data)\n",
        "  find_test_acc(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u_z5eMImMj57",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict_test(han_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dgYSOq18cH1a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R55FX-Xq3XkP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "metadata": {
        "id": "Bz0qLhb1Gi2s",
        "colab_type": "code",
        "outputId": "f9b769a1-2122-42d3-d4cb-ecba17e138fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-02 00:26:01--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.202.60.111, 52.72.245.79, 52.7.169.168, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.202.60.111|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14991793 (14M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  14.30M  62.3MB/s    in 0.2s    \n",
            "\n",
            "2019-05-02 00:26:02 (62.3 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [14991793/14991793]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2VIBupfd29Rk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8f60e7e6-c127-4544-9331-8b1ddf6e4681"
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = './Graph_HAN'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://f759b158.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HMMIu1W83CFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "c011f09c-094b-4b26-ffa4-4817f9283e01"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_cnn.png\t  HAN_weights.08-0.25.hdf5\n",
            "bbc\t\t\t  HAN_weights.08-1.18.hdf5\n",
            "bbc-fulltext.zip\t  HAN_weights.09-0.17.hdf5\n",
            "gdrive\t\t\t  HAN_weights.09-1.14.hdf5\n",
            "glove.6B.100d.txt\t  HAN_weights.11-0.16.hdf5\n",
            "glove.6B.200d.txt\t  HAN_weights.11-0.22.hdf5\n",
            "glove.6B.300d.txt\t  HAN_weights.11-1.12.hdf5\n",
            "glove.6B.50d.txt\t  HAN_weights.12-0.15.hdf5\n",
            "glove.6B.zip\t\t  HAN_weights.12-0.19.hdf5\n",
            "HAN.h5\t\t\t  HAN_weights.12-1.10.hdf5\n",
            "HAN.json\t\t  HAN_weights.13-0.13.hdf5\n",
            "HAN_weights.01-0.82.hdf5  HAN_weights.13-0.15.hdf5\n",
            "HAN_weights.01-0.92.hdf5  HAN_weights.14-0.12.hdf5\n",
            "HAN_weights.01-0.95.hdf5  HAN_weights.14-0.13.hdf5\n",
            "HAN_weights.01-1.61.hdf5  HAN_weights.16-0.13.hdf5\n",
            "HAN_weights.02-0.45.hdf5  HAN_weights.16-1.02.hdf5\n",
            "HAN_weights.02-0.47.hdf5  HAN_weights.19-0.92.hdf5\n",
            "HAN_weights.02-0.58.hdf5  HAN_weights.23-0.12.hdf5\n",
            "HAN_weights.02-1.59.hdf5  HAN_weights.23-0.91.hdf5\n",
            "HAN_weights.03-0.53.hdf5  HAN_weights.24-0.10.hdf5\n",
            "HAN_weights.04-0.32.hdf5  HAN_weights.25-0.10.hdf5\n",
            "HAN_weights.04-0.44.hdf5  HAN_weights.30-0.09.hdf5\n",
            "HAN_weights.04-1.58.hdf5  HAN_weights.31-0.89.hdf5\n",
            "HAN_weights.05-0.29.hdf5  HAN_weights.33-0.86.hdf5\n",
            "HAN_weights.05-0.30.hdf5  HAN_weights.34-0.82.hdf5\n",
            "HAN_weights.05-1.46.hdf5  ngrok\n",
            "HAN_weights.06-0.31.hdf5  ngrok-stable-linux-amd64.zip\n",
            "HAN_weights.06-1.32.hdf5  out.txt\n",
            "HAN_weights.07-0.19.hdf5  sample_data\n",
            "HAN_weights.08-0.16.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yxpBpPCy3Om5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}